{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710c7d0e",
   "metadata": {},
   "source": [
    "# üîó Data Merging Notebook ‚Äì Milestone 2\n",
    "\n",
    "**Project:** Gold Pathfinder ML Project  \n",
    "**Notebook:** `02_data_merging.ipynb`  \n",
    "\n",
    "This notebook documents how the **cleaned per-type datasets** are combined\n",
    "into a **single unified dataset**:\n",
    "\n",
    "```text\n",
    "1_datasets/processed/gold_assays_final.csv\n",
    "```\n",
    "\n",
    "It mirrors the merge logic in:\n",
    "\n",
    "```text\n",
    "2_data_preparation/scripts/data_preparation.py\n",
    "```\n",
    "\n",
    "and serves as a transparent, visual version for ELO2 evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "CLEANED_DIR = PROJECT_ROOT / '1_datasets' / 'cleaned'\n",
    "PROCESSED_DIR = PROJECT_ROOT / '1_datasets' / 'processed'\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PROJECT_ROOT, CLEANED_DIR, PROCESSED_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ccd3c4",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load Cleaned Per-Type Datasets\n",
    "\n",
    "We expect the following files in `1_datasets/cleaned/`:\n",
    "\n",
    "- `core_assays_clean.csv`\n",
    "- `rc_assays_clean.csv`\n",
    "- `chip_assays_clean.csv`\n",
    "- `trench_assays_clean.csv`\n",
    "- `grab_assays_clean.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ad36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'core': CLEANED_DIR / 'core_assays_clean.csv',\n",
    "    'rc': CLEANED_DIR / 'rc_assays_clean.csv',\n",
    "    'chip': CLEANED_DIR / 'chip_assays_clean.csv',\n",
    "    'trench': CLEANED_DIR / 'trench_assays_clean.csv',\n",
    "    'grab': CLEANED_DIR / 'grab_assays_clean.csv',\n",
    "}\n",
    "\n",
    "for name, path in files.items():\n",
    "    print(name, '->', path, 'exists:', path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for name, path in files.items():\n",
    "    if path.exists():\n",
    "        df = pd.read_csv(path)\n",
    "        df['sample_type'] = df.get('sample_type', name)\n",
    "        dfs[name] = df\n",
    "        print(f'Loaded {name}: {df.shape[0]} rows, {df.shape[1]} columns')\n",
    "    else:\n",
    "        print(f'WARNING: {name} file is missing, skipping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6779f",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Harmonize Columns and Merge\n",
    "\n",
    "We build the union of all columns, reindex each dataframe, and then\n",
    "concatenate them into a single table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74284fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dfs:\n",
    "    raise RuntimeError('No cleaned datasets loaded. Please check CLEANED_DIR.')\n",
    "\n",
    "all_cols = sorted(set().union(*[df.columns for df in dfs.values()]))\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_dfs = [df.reindex(columns=all_cols) for df in dfs.values()]\n",
    "final_df = pd.concat(aligned_dfs, ignore_index=True)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5721b00f",
   "metadata": {},
   "source": [
    "Quick preview of the final merged dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bec04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf0834c",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Basic Quality Checks\n",
    "\n",
    "- Missing `sample_id` values\n",
    "- Presence of `sample_type`\n",
    "- Range of `au_ppm` if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['sample_id'].isna().sum(), final_df['sample_type'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'au_ppm' in final_df.columns:\n",
    "    print('Min Au:', final_df['au_ppm'].min())\n",
    "    print('Max Au:', final_df['au_ppm'].max())\n",
    "else:\n",
    "    print(\"WARNING: 'au_ppm' column not found in final_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5dfb2",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Save Final Dataset\n",
    "\n",
    "We now save the merged dataset to:\n",
    "\n",
    "```text\n",
    "1_datasets/processed/gold_assays_final.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25397f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_out = PROCESSED_DIR / 'gold_assays_final.csv'\n",
    "final_df.to_csv(final_out, index=False)\n",
    "final_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea7b7be",
   "metadata": {},
   "source": [
    "## ‚úÖ Milestone 2 Output\n",
    "\n",
    "At this point, we have:\n",
    "\n",
    "- Cleaned per-type datasets in `1_datasets/cleaned/`\n",
    "- A unified merged dataset in `1_datasets/processed/gold_assays_final.csv`\n",
    "\n",
    "This completes the **Data Collection & Preparation (Milestone 2)** stage.\n",
    "Next, in Milestone 3, we will perform **exploratory data analysis (EDA)**\n",
    "and start identifying candidate **geochemical pathfinder elements**.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
