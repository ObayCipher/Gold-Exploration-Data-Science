{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196c71ea",
   "metadata": {},
   "source": [
    "# üîç Exploratory Data Analysis ‚Äì Overview\n",
    "\n",
    "**Project:** Gold Pathfinder ML Project  \n",
    "**Notebook:** `01_eda_overview.ipynb`  \n",
    "**Milestone:** 3 ‚Äì Data Analysis / Exploration\n",
    "\n",
    "This notebook provides a **first look** at the prepared dataset:\n",
    "\n",
    "- Load `gold_assays_final.csv`\n",
    "- Inspect structure, columns, and dtypes\n",
    "- Check basic statistics and missing values\n",
    "- Summarize sample types and anomalies\n",
    "\n",
    "It is the starting point for all deeper EDA and modeling work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15717fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 80)\n",
    "pd.set_option('display.width', 140)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:0.4f}')\n",
    "\n",
    "# Assume this notebook lives in 3_data_exploration/\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "DATA_PROCESSED = PROJECT_ROOT / '1_datasets' / 'processed'\n",
    "DATA_PROCESSED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b658045",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load Final Processed Dataset\n",
    "\n",
    "We load the unified assay dataset created in Milestone 2:\n",
    "\n",
    "```text\n",
    "1_datasets/processed/gold_assays_final.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef1e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = DATA_PROCESSED / 'gold_assays_final.csv'\n",
    "final_path, final_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(final_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a557dd",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Basic Shape & Structure\n",
    "\n",
    "- Number of rows and columns  \n",
    "- Column names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd40943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0289c6b",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Missing Values Overview\n",
    "\n",
    "We check how many missing values each column contains.\n",
    "This helps prioritize cleaning or imputation in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea44d95",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Key Categorical Fields\n",
    "\n",
    "We inspect value counts for important categorical fields such as:\n",
    "\n",
    "- `sample_type` (core, rc, chip, trench, grab)\n",
    "- `project_area`\n",
    "- `anomaly_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [c for c in ['sample_type', 'project_area', 'anomaly_id'] if c in df.columns]\n",
    "for col in categorical_cols:\n",
    "    print(f'\\nValue counts for {col}:')\n",
    "    print(df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9f99a",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Numerical Summary\n",
    "\n",
    "We compute descriptive statistics for key numerical columns such as:\n",
    "\n",
    "- `au_ppm` (gold)\n",
    "- pathfinder elements: `as_ppm`, `sb_ppm`, `bi_ppm`, `cu_ppm`, `zn_ppm`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5984ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols].describe().T.sort_values('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceefdb0",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Save a Lightweight Profile (Optional)\n",
    "\n",
    "You can optionally save selected summary tables (e.g., missingness or\n",
    "numeric stats) into CSVs for quick reference in `3_data_exploration/outputs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b550e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path('.') / 'outputs'\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "missing.to_csv(OUTPUT_DIR / 'missing_summary.csv', header=['n_missing'])\n",
    "df[numeric_cols].describe().T.to_csv(OUTPUT_DIR / 'numeric_summary.csv')\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc653ac3",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "This notebook confirms that:\n",
    "\n",
    "- The final dataset can be loaded successfully.\n",
    "- The main structure (rows, columns, dtypes) is understood.\n",
    "- We have an overview of missing values and key categorical breakdowns.\n",
    "\n",
    "Next, we will move to **visual EDA**:\n",
    "\n",
    "- Histograms and distributions of Au and pathfinder elements.\n",
    "- Log-transformed views for skewed variables.\n",
    "- First correlation checks.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
